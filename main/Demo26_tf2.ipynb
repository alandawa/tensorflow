{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.5.2 in d:\\users\\shise\\anaconda3\\envs\\py39\\lib\\site-packages (1.5.2)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\users\\shise\\anaconda3\\envs\\py39\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for tensorflow: [Errno 2] No such file or directory: 'd:\\\\users\\\\shise\\\\anaconda3\\\\envs\\\\py39\\\\lib\\\\site-packages\\\\tensorflow-2.16.2.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (d:\\users\\shise\\anaconda3\\envs\\py39\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\users\\shise\\anaconda3\\envs\\py39\\lib\\site-packages (from pandas==1.5.2) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\users\\shise\\anaconda3\\envs\\py39\\lib\\site-packages (from pandas==1.5.2) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in d:\\users\\shise\\anaconda3\\envs\\py39\\lib\\site-packages (from pandas==1.5.2) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in d:\\users\\shise\\anaconda3\\envs\\py39\\lib\\site-packages (from python-dateutil>=2.8.1->pandas==1.5.2) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# pip install  pandas==1.5.2 scikit-learn==1.2.1 matplotlib==3.7.1 pillow==9.4.0 tensorflow==2.14.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets,layers,optimizers,Sequential,metrics\n",
    "import  os\n",
    "import glob\n",
    "\n",
    "# load mnist data\n",
    "batch_size = 256\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype(np.float32) / 255.\n",
    "train_data = tf.data.Dataset.from_tensor_slices(x_train).shuffle(batch_size*4).batch(batch_size).repeat()\n",
    "train_data_iter = iter(train_data)\n",
    "inputs_shape = [-1, 28, 28, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.n_f = 512\n",
    "        self.n_k = 4\n",
    "\n",
    "        # input z vector is [None, 100]\n",
    "        self.dense1 = keras.layers.Dense(3 * 3 * self.n_f)\n",
    "        self.conv2 = keras.layers.Conv2DTranspose(self.n_f // 2, 3, 2, 'valid')\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        self.conv3 = keras.layers.Conv2DTranspose(self.n_f // 4, self.n_k, 2, 'same')\n",
    "        self.bn3 = keras.layers.BatchNormalization()\n",
    "        self.conv4 = keras.layers.Conv2DTranspose(1, self.n_k, 2, 'same')\n",
    "        return\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # [b, 100] => [b, 3, 3, 512]\n",
    "        x = tf.nn.leaky_relu(tf.reshape(self.dense1(inputs), shape=[-1, 3, 3, self.n_f]))\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))\n",
    "        x = tf.tanh(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "class Discriminator(keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.n_f = 64\n",
    "        self.n_k = 4\n",
    "\n",
    "        # input image is [-1, 28, 28, 1]\n",
    "        self.conv1 = keras.layers.Conv2D(self.n_f, self.n_k, 2, 'same')\n",
    "        self.conv2 = keras.layers.Conv2D(self.n_f * 2, self.n_k, 2, 'same')\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        self.conv3 = keras.layers.Conv2D(self.n_f * 4, self.n_k, 2, 'same')\n",
    "        self.bn3 = keras.layers.BatchNormalization()\n",
    "        self.flatten4 = keras.layers.Flatten()\n",
    "        self.dense4 = keras.layers.Dense(1)\n",
    "        return\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = tf.nn.leaky_relu(self.conv1(inputs))\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))\n",
    "        x = self.dense4(self.flatten4(x))\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Generator()\n",
    "d = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a4d74e7dc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = g(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00024611]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "decision = d(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             multiple                  235008    \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2D  multiple                  1179904   \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  multiple                  1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2D  multiple                  524416    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  multiple                  512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2D  multiple                  2049      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1942913 (7.41 MB)\n",
      "Trainable params: 1942145 (7.41 MB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           multiple                  1088      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           multiple                  131200    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  multiple                  512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           multiple                  524544    \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  multiple                  1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 662465 (2.53 MB)\n",
      "Trainable params: 661697 (2.52 MB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "z_dim = 50\n",
    "epochs = 1000\n",
    "batch_size = 128\n",
    "learning_rate = 0.0002\n",
    "is_training = True\n",
    "\n",
    "generator = Generator()\n",
    "generator.build(input_shape=(batch_size, z_dim))\n",
    "generator.summary()\n",
    "discriminator = Discriminator()\n",
    "discriminator.build(input_shape=(batch_size, 28, 28, 1))\n",
    "discriminator.summary()\n",
    "\n",
    "# prepare optimizer\n",
    "d_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
    "g_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_real(logits):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n",
    "                                                                  labels=tf.ones_like(logits)))\n",
    "\n",
    "def loss_fake(logits):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n",
    "                                                                  labels=tf.zeros_like(logits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_loss(generator, discriminator, input_noise, real_image, is_trainig):\n",
    "    fake_image = generator(input_noise, is_trainig)\n",
    "    d_real_logits = discriminator(real_image, is_trainig)\n",
    "    d_fake_logits = discriminator(fake_image, is_trainig)\n",
    "\n",
    "    d_loss_real = loss_real(d_real_logits)\n",
    "    d_loss_fake = loss_fake(d_fake_logits)\n",
    "    loss = d_loss_real + d_loss_fake\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_loss(generator, discriminator, input_noise, is_trainig):\n",
    "    fake_image = generator(input_noise, is_trainig)\n",
    "    fake_loss = discriminator(fake_image, is_trainig)\n",
    "    loss = loss_real(fake_loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 d loss: 1.7108750343322754 g loss: 1.7975037097930908\n",
      "100 d loss: 0.6890132427215576 g loss: 2.0370752811431885\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11524\\504406206.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0md_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mg_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\shise\\anaconda3\\envs\\py39\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1061\u001b[0m               output_gradients))\n\u001b[0;32m   1062\u001b[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001b[0;32m   1063\u001b[0m                           for x in output_gradients]\n\u001b[0;32m   1064\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1065\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1066\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\shise\\anaconda3\\envs\\py39\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     raise ValueError(\n\u001b[0;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\shise\\anaconda3\\envs\\py39\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gradient_tape/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\shise\\anaconda3\\envs\\py39\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    589\u001b[0m           \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m           data_format=data_format),\n\u001b[1;32m--> 593\u001b[1;33m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[0m\u001b[0;32m    594\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m           \u001b[0mshape_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\shise\\anaconda3\\envs\\py39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1631\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1634\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1635\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1636\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m       return conv2d_backprop_filter_eager_fallback(\n\u001b[0;32m   1638\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    batch_x = next(train_data_iter)\n",
    "    batch_x = tf.reshape(batch_x, shape=inputs_shape)\n",
    "    batch_x = batch_x * 2.0 - 1.0\n",
    "    batch_z = tf.random.normal(shape=[batch_size, z_dim])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        d_loss = dis_loss(generator, discriminator, batch_z, batch_x, is_training)\n",
    "    grads = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        g_loss = gen_loss(generator, discriminator, batch_z, is_training)\n",
    "    grads = tape.gradient(g_loss, generator.trainable_variables)\n",
    "    g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "\n",
    "        print(epoch, 'd loss:', float(d_loss), 'g loss:', float(g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m noise \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m])\n\u001b[0;32m      2\u001b[0m generated_image \u001b[38;5;241m=\u001b[39m generator(noise, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(generated_image[\u001b[38;5;241m0\u001b[39m, :, :, \u001b[38;5;241m0\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "noise = tf.random.normal([1, 50])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
