{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def prepare_data(data_file_name):\n",
    "    \"\"\"\n",
    "    Responsible for cleaning the data file provided from the UCI machine\n",
    "    learning repository here: http://archive.ics.uci.edu/ml/datasets/Mushroom.\n",
    "    The function then produces two CSV files appropriately formatted to be\n",
    "    used in TensorFlow where the CSV files split with respect to\n",
    "    training and testing data.\n",
    "    \"\"\"\n",
    "\n",
    "    # The header is formed from the 'agaricus-lepiota.name' file found on\n",
    "    # http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "    header = ['class', 'cap_shape', 'cap_surface',\n",
    "              'cap_color', 'bruises', 'odor', 'gill_attachment',\n",
    "              'gill_spacing', 'gill_size', 'gill_color', 'stalk_shape',\n",
    "              'stalk_root', 'stalk_surface_above_ring',\n",
    "              'stalk_surface_below_ring', 'stalk_color_above_ring',\n",
    "              'stalk_color_below_ring', 'veil_type', 'veil_color',\n",
    "              'ring_number', 'ring_type', 'spore_print_color',\n",
    "              'population', 'habitat']\n",
    "    df = pd.read_csv(data_file_name, sep=',', names=header)\n",
    "\n",
    "    # Entries with a '?' indicate a missing piece of data, and\n",
    "    # these entries are dropped from our dataset.\n",
    "    df.replace('?', np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # The class of poisonous or edible is indicated in the data as\n",
    "    # either 'p' or 'e' respectively. We require that this is numeric,\n",
    "    # and therefore use '0' to indicate poisonous (or not edible) and\n",
    "    # '1' to indicate edible.\n",
    "    df['class'].replace('p', 0, inplace=True)\n",
    "    df['class'].replace('e', 1, inplace=True)\n",
    "\n",
    "    # Since we are dealing with non-numeric feature data, or in other\n",
    "    # words, categorical data, we need to replace these with numerical\n",
    "    # equivalents. Pandas has a nice function called \"get_dummies\" that\n",
    "    # performs this task.\n",
    "    cols_to_transform = header[1:]\n",
    "    df = pd.get_dummies(df, columns=cols_to_transform)\n",
    "\n",
    "    # We can now split the data into two separate data frames,\n",
    "    # one for training, which will constitute the bulk of the\n",
    "    # data, and one for testing.\n",
    "    df_train, df_test = train_test_split(df, test_size=0.1)\n",
    "\n",
    "    # Determine the number of rows and columns in each of the\n",
    "    # data frames.\n",
    "    num_train_entries = df_train.shape[0]\n",
    "    num_train_features = df_train.shape[1] - 1\n",
    "\n",
    "    num_test_entries = df_test.shape[0]\n",
    "    num_test_features = df_test.shape[1] - 1\n",
    "\n",
    "    # The data frames are written as a temporary CSV file, as we still\n",
    "    # need to modify the header row to include the number of rows and\n",
    "    # columns present in the training and testing CSV files.\n",
    "    df_train.to_csv('mushroom_train.csv', index=False)\n",
    "    df_test.to_csv('mushroom_test.csv', index=False)\n",
    "\n",
    "    \n",
    "MUSHROOM_DATA_FILE = \"agaricus-lepiota.data\"\n",
    "\n",
    "# Prepare the mushroom data for TensorFlow by\n",
    "# creating two train / test CSV files.\n",
    "prepare_data(MUSHROOM_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class  cap_shape_b  cap_shape_c  cap_shape_f  cap_shape_k  cap_shape_s  \\\n",
      "0      0            1            0            0            0            0   \n",
      "1      0            0            0            0            0            0   \n",
      "2      1            0            0            0            0            0   \n",
      "3      1            0            0            0            0            0   \n",
      "4      1            0            0            1            0            0   \n",
      "\n",
      "   cap_shape_x  cap_surface_f  cap_surface_g  cap_surface_s  ...  \\\n",
      "0            0              0              0              1  ...   \n",
      "1            1              0              0              0  ...   \n",
      "2            1              1              0              0  ...   \n",
      "3            1              1              0              0  ...   \n",
      "4            0              0              0              0  ...   \n",
      "\n",
      "   population_n  population_s  population_v  population_y  habitat_d  \\\n",
      "0             0             0             1             0          0   \n",
      "1             0             0             0             1          0   \n",
      "2             0             0             0             1          1   \n",
      "3             0             0             0             1          1   \n",
      "4             0             0             0             1          1   \n",
      "\n",
      "   habitat_g  habitat_l  habitat_m  habitat_p  habitat_u  \n",
      "0          0          0          1          0          0  \n",
      "1          1          0          0          0          0  \n",
      "2          0          0          0          0          0  \n",
      "3          0          0          0          0          0  \n",
      "4          0          0          0          0          0  \n",
      "\n",
      "[5 rows x 99 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('mushroom_train.csv')\n",
    "print(df_train.head())\n",
    "\n",
    "train_label = np.array(df_train['class'])\n",
    "train_data =  np.array(df_train.drop('class', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class  cap_shape_b  cap_shape_c  cap_shape_f  cap_shape_k  cap_shape_s  \\\n",
      "0      0            0            0            0            0            0   \n",
      "1      1            0            0            1            0            0   \n",
      "2      0            0            0            1            0            0   \n",
      "3      1            0            0            1            0            0   \n",
      "4      0            0            0            0            0            0   \n",
      "\n",
      "   cap_shape_x  cap_surface_f  cap_surface_g  cap_surface_s  ...  \\\n",
      "0            1              1              0              0  ...   \n",
      "1            0              0              0              1  ...   \n",
      "2            0              0              0              0  ...   \n",
      "3            0              0              0              0  ...   \n",
      "4            1              0              0              0  ...   \n",
      "\n",
      "   population_n  population_s  population_v  population_y  habitat_d  \\\n",
      "0             0             0             0             1          0   \n",
      "1             0             1             0             0          0   \n",
      "2             0             0             0             1          0   \n",
      "3             0             0             0             1          0   \n",
      "4             0             0             1             0          1   \n",
      "\n",
      "   habitat_g  habitat_l  habitat_m  habitat_p  habitat_u  \n",
      "0          0          0          0          1          0  \n",
      "1          1          0          0          0          0  \n",
      "2          0          0          0          1          0  \n",
      "3          0          0          0          1          0  \n",
      "4          0          0          0          0          0  \n",
      "\n",
      "[5 rows x 99 columns]\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('mushroom_test.csv')\n",
    "print(df_test.head())\n",
    "test_label = np.array(df_test['class'])\n",
    "test_data =  np.array(df_test.drop('class', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5079, 98)   (5079,)\n",
      "(565, 98)   (565,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, ' ', train_label.shape)\n",
    "print(test_data.shape, ' ', test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                3168      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4290 (16.76 KB)\n",
      "Trainable params: 4290 (16.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(98,)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "56/56 - 1s - loss: 0.3508 - accuracy: 0.8515 - val_loss: 0.1067 - val_accuracy: 0.9829 - 934ms/epoch - 17ms/step\n",
      "Epoch 2/10\n",
      "56/56 - 0s - loss: 0.0478 - accuracy: 0.9958 - val_loss: 0.0197 - val_accuracy: 0.9993 - 126ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "56/56 - 0s - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000 - 121ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "56/56 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000 - 124ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "56/56 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000 - 124ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "56/56 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000 - 122ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "56/56 - 0s - loss: 9.9041e-04 - accuracy: 1.0000 - val_loss: 9.6041e-04 - val_accuracy: 1.0000 - 121ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "56/56 - 0s - loss: 7.2023e-04 - accuracy: 1.0000 - val_loss: 7.2796e-04 - val_accuracy: 1.0000 - 118ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "56/56 - 0s - loss: 5.4917e-04 - accuracy: 1.0000 - val_loss: 5.6805e-04 - val_accuracy: 1.0000 - 122ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "56/56 - 0s - loss: 4.3420e-04 - accuracy: 1.0000 - val_loss: 4.6350e-04 - val_accuracy: 1.0000 - 122ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_label, batch_size=64, epochs=10, validation_split=0.3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\shise\\anaconda3\\envs\\py39\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('dnn_mushroom_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 3.7441e-04 - accuracy: 1.0000\n",
      "[0.0003744073328562081, 1.0]\n"
     ]
    }
   ],
   "source": [
    "new_model = keras.models.load_model('dnn_mushroom_model.h5')\n",
    "result = new_model.evaluate(test_data, test_label)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
